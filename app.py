# -*- coding: utf-8 -*-
"""
Unified Business Data Analyzer - COMPLETE VERSION
‡∏£‡∏ß‡∏°: Complaint Chatbot + Single/Multi-File Data Analyzer + Chat Mode
"""

import streamlit as st
import pandas as pd
import json
import requests
import sqlite3
import plotly.express as px
import plotly.graph_objects as go
from typing import Dict, List, Optional, Any
import time
from datetime import datetime
import hashlib
from io import BytesIO
import os
import logging

# Import PandasAI
try:
    from pandasai import SmartDataframe
    from pandasai.llm import LLM
    PANDASAI_AVAILABLE = True
except ImportError:
    PANDASAI_AVAILABLE = False

# ==================== Configuration ====================
st.set_page_config(
    page_title="üéØ Business Platform",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded"
)

DATABASE = 'complaints.db'

# Enhanced CSS
st.markdown("""
<style>
    .main-header {
        text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem 1rem;
        border-radius: 15px;
        color: white;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .mode-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
        border-left: 5px solid #667eea;
        transition: all 0.3s;
    }
    .mode-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 6px 12px rgba(0,0,0,0.15);
    }
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin: 0.8rem 0;
        animation: fadeIn 0.3s ease-in;
    }
    .user-message {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        border-left: 4px solid #2196f3;
    }
    .ai-message {
        background: linear-gradient(135deg, #f3e5f5 0%, #e1bee7 100%);
        border-left: 4px solid #9c27b0;
    }
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    .file-card {
        background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 100%);
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #ff9800;
    }
    .stButton>button {
        border-radius: 8px;
        font-weight: 500;
        transition: all 0.3s;
    }
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    }
</style>
""", unsafe_allow_html=True)

# ==================== Database Functions ====================
def init_db():
    """Initialize complaints database with new structure"""
    with sqlite3.connect(DATABASE) as conn:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏Å‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='complaints'")
        table_exists = cursor.fetchone() is not None
        
        if table_exists:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            cursor.execute("PRAGMA table_info(complaints)")
            columns = [column[1] for column in cursor.fetchall()]
            
            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏Å‡πà‡∏≤ ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡∏∞‡∏¢‡πâ‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            if 'complaint' in columns and 'subject' not in columns:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS complaints_new (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        subject TEXT NOT NULL,
                        details TEXT NOT NULL,
                        name TEXT NOT NULL,
                        category TEXT,
                        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                # ‡∏¢‡πâ‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏Å‡πà‡∏≤‡πÑ‡∏õ‡πÉ‡∏´‡∏°‡πà
                cursor.execute('''
                    INSERT INTO complaints_new (subject, details, name, category, timestamp)
                    SELECT 
                        SUBSTR(complaint, 1, 100) as subject,
                        complaint as details,
                        name,
                        NULL as category,
                        timestamp
                    FROM complaints
                ''')
                
                # ‡∏•‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
                conn.execute('DROP TABLE complaints')
                conn.execute('ALTER TABLE complaints_new RENAME TO complaints')
                conn.commit()
                
                st.success("‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
            elif 'subject' not in columns:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS complaints (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        subject TEXT NOT NULL,
                        details TEXT NOT NULL,
                        name TEXT NOT NULL,
                        category TEXT,
                        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                conn.commit()
        else:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
            conn.execute('''
                CREATE TABLE IF NOT EXISTS complaints (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    subject TEXT NOT NULL,
                    details TEXT NOT NULL,
                    name TEXT NOT NULL,
                    category TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            conn.commit()

def save_complaint(subject: str, details: str, name: str, category: str = None) -> int:
    """Save complaint to database with new structure"""
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡πà‡∏≤‡∏á
    if not subject or not details or not name:
        raise ValueError("‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤")
    
    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    subject = subject.strip()[:100]  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠
    details = details.strip()[:2000]  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
    name = name.strip()[:100]  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ä‡∏∑‡πà‡∏≠
    
    with sqlite3.connect(DATABASE) as conn:
        cursor = conn.cursor()
        cursor.execute(
            "INSERT INTO complaints (subject, details, name, category) VALUES (?, ?, ?, ?)",
            (subject, details, name, category)
        )
        conn.commit()
        return cursor.lastrowid

def get_complaints(limit: int = 100) -> List[Dict]:
    """Get complaints from database with new structure"""
    with sqlite3.connect(DATABASE) as conn:
        conn.row_factory = sqlite3.Row
        rows = conn.execute(
            'SELECT id, subject, details, name, category, timestamp FROM complaints ORDER BY timestamp DESC LIMIT ?',
            (limit,)
        ).fetchall()
        return [dict(row) for row in rows]

def get_recent_complaints_context(limit: int = 3) -> str:
    """Get recent complaints as context for RAG with new structure"""
    complaints = get_complaints(limit)
    return "\n".join([f"- {c['subject']}: {c['details']}" for c in complaints])

# ==================== Session State ====================
def init_session_state():
    """Initialize session state"""
    defaults = {
        'mode': 'home',
        'dataframes': {},
        'chat_history': [],
        'complaint_history': [],
        'new_mode_history': [],
        'llm': None,
        'api_stats': {'requests': 0, 'errors': 0, 'cache_hits': 0},
        'question_cache': {},
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# ==================== OpenRouter LLM ====================
def create_llm(api_key: str, model: str):
    """Create and return an OpenRouter LLM instance"""
    if not PANDASAI_AVAILABLE:
        raise RuntimeError("pandasai ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á ‡πÅ‡∏ï‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î‡∏ô‡∏µ‡πâ")
    
    # ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ LLM ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
    class OpenRouterDirectLLM(LLM):
        """OpenRouter LLM using direct HTTP requests"""
        
        def __init__(
            self, 
            api_token: str, 
            model: str = "anthropic/claude-3-haiku",
            temperature: float = 0.2,
            max_tokens: int = 2000,
            **kwargs
        ):
            self.api_token = api_token
            self.model = model
            self.temperature = temperature
            self.max_tokens = max_tokens
            self.kwargs = kwargs
            self.request_count = 0
            self.error_count = 0

        def call(self, instruction: str, context: str = "") -> str:
            """Call OpenRouter API"""
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á system prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö pandasai
            system_prompt = {
                "role": "system",
                "content": (
                    "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç "
                    "‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå"
                )
            }
            
            user_content = f"{context}\n\n{instruction}" if context else instruction
            
            messages = [
                system_prompt,
                {
                    "role": "user",
                    "content": user_content
                }
            ]
            
            headers = {
                "Authorization": f"Bearer {self.api_token}",
                "Content-Type": "application/json",
            }
            
            payload = {
                "model": self.model,
                "messages": messages,
                "temperature": self.temperature,
                "max_tokens": self.max_tokens,
            }
            
            try:
                self.request_count += 1
                st.session_state.api_stats['requests'] += 1
                
                response = requests.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=60
                )
                
                response.raise_for_status()
                data = response.json()
                
                if 'choices' in data and len(data['choices']) > 0:
                    return data['choices'][0]['message']['content']
                else:
                    return "‚ùå ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI"
                    
            except Exception as e:
                self.error_count += 1
                st.session_state.api_stats['errors'] += 1
                return f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"

        @property
        def type(self) -> str:
            return "openrouter"
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° properties ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö pandasai LLM
        @property
        def model_name(self) -> str:
            return self.model
        
        def generate(self, prompt: str) -> str:
            """Generate response using OpenRouter API"""
            headers = {
                "Authorization": f"Bearer {self.api_token}",
                "Content-Type": "application/json",
            }
            
            messages = [
                {
                    "role": "user",
                    "content": prompt
                }
            ]
            
            payload = {
                "model": self.model,
                "messages": messages,
                "temperature": self.temperature,
                "max_tokens": self.max_tokens,
            }
            
            try:
                response = requests.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=60
                )
                
                response.raise_for_status()
                data = response.json()
                
                if 'choices' in data and len(data['choices']) > 0:
                    return data['choices'][0]['message']['content']
                else:
                    return "‚ùå ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI"
                    
            except Exception as e:
                return f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"

    return OpenRouterDirectLLM(api_token=api_key, model=model)

# ==================== File Processing Functions ====================
def load_json_file(file_content: bytes) -> tuple:
    """Load JSON file and return DataFrame"""
    try:
        raw_data = json.loads(file_content.decode('utf-8'))
        
        if isinstance(raw_data, list):
            if len(raw_data) == 0:
                return pd.DataFrame(), "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤"
            
            if isinstance(raw_data[0], list):
                num_cols = len(raw_data[0])
                columns = [f"col_{i+1}" for i in range(num_cols)]
                df = pd.DataFrame(raw_data, columns=columns)
            else:
                df = pd.DataFrame(raw_data)
                
        elif isinstance(raw_data, dict):
            df = pd.DataFrame([raw_data])
        else:
            return pd.DataFrame(), "‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"
        
        return df, ""
        
    except Exception as e:
        return pd.DataFrame(), f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"

def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """Clean dataframe"""
    if df.empty:
        return df
    
    df_clean = df.copy()
    
    # Convert complex types to string
    for col in df_clean.columns:
        if df_clean[col].apply(lambda x: isinstance(x, (list, dict))).any():
            df_clean[col] = df_clean[col].apply(
                lambda x: str(x) if isinstance(x, (list, dict)) else x
            )
    
    # Clean text columns
    text_cols = df_clean.select_dtypes(include=['object']).columns
    for col in text_cols:
        df_clean[col] = df_clean[col].astype(str).str.strip()
    
    return df_clean

def ask_question_about_data(question: str, dataframes: Dict[str, pd.DataFrame], llm: "LLM") -> str:
    """Ask question about data using SmartDataframe"""
    
    # Check cache
    q_hash = hashlib.md5(question.encode()).hexdigest()
    if q_hash in st.session_state.question_cache:
        st.session_state.api_stats['cache_hits'] += 1
        return st.session_state.question_cache[q_hash] + "\n\nüíæ (‡∏à‡∏≤‡∏Å‡πÅ‡∏Ñ‡∏ä)"
    
    try:
        df_list = list(dataframes.values())
        
        if len(df_list) == 0:
            return "‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"
        
        config = {
            "llm": llm,
            "verbose": False,
            "enable_cache": True,
            "conversational": False,
            "save_charts": False,
        }
        
        # Create SmartDataframe
        if len(df_list) == 1:
            sdf = SmartDataframe(df_list[0], config=config)
        else:
            sdf = SmartDataframe(df_list, config=config)
        
        # Ask question
        response = sdf.chat(question)
        
        # Format response
        if response is None:
            answer = "‚ùå ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI"
        elif isinstance(response, pd.DataFrame):
            answer = "üìä ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:\n\n" + response.to_markdown(index=False)
        elif isinstance(response, (int, float)):
            answer = f"‚úÖ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: {response:,.2f}"
        else:
            answer = str(response)
        
        # Cache successful response
        if not answer.startswith("‚ùå"):
            st.session_state.question_cache[q_hash] = answer
        
        return answer
        
    except Exception as e:
        return f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}\n\nüí° ‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏ö‡∏ö‡∏≠‡∏∑‡πà‡∏ô ‡πÄ‡∏ä‡πà‡∏ô:\n- ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 10 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å\n- ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"

# ==================== Chat Mode Handler ====================
def handle_new_mode_chat(api_key: str, model: str):
    """Handle new mode chatbot interface"""
    
    st.subheader("üí¨ ‡πÇ‡∏´‡∏°‡∏î‡πÅ‡∏ä‡∏ó OpenRouter")
    
    # Initialize LLM if needed
    if not st.session_state.llm and api_key:
        try:
            st.session_state.llm = create_llm(api_key, model)
        except Exception as e:
            st.error(f"‚ùå ‡∏™‡∏£‡πâ‡∏≤‡∏á LLM ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")
            return
    
    # Chat interface with instructions
    with st.expander("üí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", expanded=False):
        st.markdown(""" 
        1. ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á
        2. ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° "‡∏™‡πà‡∏á" ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏î Enter
        3. AI ‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
        """)
    
    # Use Form for Enter key support
    with st.form("new_mode_form", clear_on_submit=True):
        col1, col2 = st.columns([5, 1])
        
        with col1:
            user_message = st.text_input(
                "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°",
                placeholder="‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ñ‡∏≤‡∏°...",
                label_visibility="collapsed"
            )
        
        with col2:
            send_btn = st.form_submit_button("üì§ ‡∏™‡πà‡∏á", type="primary", use_container_width=True)
    
    # Action buttons
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", use_container_width=True):
            st.session_state.new_mode_history = []
            st.success("‚úÖ ‡∏•‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏•‡πâ‡∏ß")
            st.rerun()
    
    with col2:
        if st.button("üíæ ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥", use_container_width=True):
            if st.session_state.new_mode_history:
                df = pd.DataFrame(st.session_state.new_mode_history)
                csv = df.to_csv(index=False)
                st.download_button(
                    "üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV",
                    csv,
                    "chat_history.csv",
                    "text/csv",
                    use_container_width=True
                )
    
    # Process message
    if send_btn and user_message and st.session_state.llm:
        # Add user message
        st.session_state.new_mode_history.append({
            "role": "user",
            "content": user_message,
            "timestamp": datetime.now().strftime("%H:%M:%S")
        })
        
        # Build conversation
        full_conversation = "\n\n".join([
            f"{m['role']}: {m['content']}" 
            for m in st.session_state.new_mode_history
        ])
        
        with st.spinner("ü§î AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö..."):
            bot_reply = st.session_state.llm.call(full_conversation)
        
        st.session_state.new_mode_history.append({
            "role": "assistant",
            "content": bot_reply,
            "timestamp": datetime.now().strftime("%H:%M:%S")
        })
        
        st.rerun()
    
    # Display chat history
    if st.session_state.new_mode_history:
        st.markdown("---")
        st.subheader("üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤")
        
        for msg in st.session_state.new_mode_history[-10:]:
            if msg['role'] == 'user':
                st.markdown(f"""
                <div class="chat-message user-message">
                    <strong>üë§ ‡∏Ñ‡∏∏‡∏ì [{msg.get('timestamp', '')}]:</strong><br/>
                    {msg['content']}
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="chat-message ai-message">
                    <strong>ü§ñ AI [{msg.get('timestamp', '')}]:</strong><br/>
                    {msg['content']}
                </div>
                """, unsafe_allow_html=True)

# ==================== Complaint Chat Handler ====================
def extract_complaint_info(conversation_history: List[Dict]) -> tuple:
    """Extract complaint info from conversation with new order: 1.‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á 2.‡πÅ‡∏à‡πâ‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î 3.‡πÅ‡∏à‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠"""
    user_messages = [m['content'] for m in conversation_history if m['role'] == 'user']
    
    if len(user_messages) < 3:
        return None, None, None
    
    # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏Å‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô (‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠)
    subject = user_messages[0].strip()
    
    # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡∏Ñ‡∏∑‡∏≠‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
    details = user_messages[1].strip()
    
    # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ñ‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
    name = user_messages[-1].strip()
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
    if len(subject) < 2 or len(details) < 10 or len(name) < 2:
        return None, None, None
    
    return subject, details, name

def validate_complaint_data(subject: str, details: str, name: str) -> tuple:
    """Validate complaint data and return (is_valid, error_message)"""
    if not subject or not subject.strip():
        return False, "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"
    
    if not details or not details.strip():
        return False, "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"
    
    if not name or not name.strip():
        return False, "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"
    
    if len(subject.strip()) < 2:
        return False, "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£"
    
    if len(details.strip()) < 10:
        return False, "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 10 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£"
    
    if len(name.strip()) < 2:
        return False, "‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£"
    
    return True, None

def handle_complaint_chat(api_key: str, model: str):
    """Handle complaint chatbot interface with new order: 1.‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á 2.‡πÅ‡∏à‡πâ‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î 3.‡πÅ‡∏à‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠"""
    
    st.subheader("üí¨ ‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô")
    
    # Initialize LLM if needed
    if not st.session_state.llm and api_key:
        try:
            st.session_state.llm = create_llm(api_key, model)
        except Exception as e:
            st.error(f"‚ùå ‡∏™‡∏£‡πâ‡∏≤‡∏á LLM ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")
            return
    
    # Chat interface
    with st.expander("üí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", expanded=False):
        st.markdown(""" 
        1. ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô (‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠)
        2. ‡πÅ‡∏à‡πâ‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
        3. ‡πÅ‡∏à‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
        4. ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö
        """)
    
    # Use Form
    with st.form("complaint_form", clear_on_submit=True):
        col1, col2 = st.columns([5, 1])
        
        with col1:
            user_message = st.text_input(
                "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°",
                placeholder="‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á...",
                label_visibility="collapsed"
            )
        
        with col2:
            send_btn = st.form_submit_button("üì§ ‡∏™‡πà‡∏á", type="primary", use_container_width=True)
    
    # Action buttons
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", use_container_width=True):
            st.session_state.complaint_history = []
            st.success("‚úÖ ‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß")
    
    with col2:
        if st.button("üìã ‡∏î‡∏π‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", use_container_width=True):
            complaints = get_complaints(50)
            if complaints:
                st.dataframe(
                    pd.DataFrame(complaints),
                    use_container_width=True,
                    height=300
                )
            else:
                st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô")
    
    # Process message
    if send_btn and user_message and st.session_state.llm:
        # Add user message
        st.session_state.complaint_history.append({
            "role": "user",
            "content": user_message
        })
        
        # Get RAG context
        rag_context = get_recent_complaints_context()
        
        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
        user_messages_count = len([m for m in st.session_state.complaint_history if m['role'] == 'user'])
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
        if user_messages_count == 1:
            # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:
{rag_context}

‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ß‡πà‡∏≤: "{user_message}"

‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ô‡∏µ‡πâ
‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á
"""
        elif user_messages_count == 2:
            # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô

‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏à‡πâ‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏ß‡πà‡∏≤: "{user_message}"

‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á
"""
        else:
            # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô

‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏à‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡πà‡∏≤: "{user_message}"

‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì
‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á
"""
        
        messages = [{"role": "system", "content": prompt}]
        
        full_conversation = "\n\n".join([
            f"{m['role']}: {m['content']}" for m in messages
        ])
        
        with st.spinner("ü§î AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö..."):
            bot_reply = st.session_state.llm.call(full_conversation)
        
        st.session_state.complaint_history.append({
            "role": "assistant",
            "content": bot_reply
        })
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        if user_messages_count == 1:
            st.info("üìù ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô (‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠) - ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‚úÖ")
        elif user_messages_count == 2:
            st.info("üìù ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô - ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‚úÖ")
        elif user_messages_count >= 3:
            st.info("üìù ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô - ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‚úÖ")
            
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
            subject, details, name = extract_complaint_info(st.session_state.complaint_history)
            
            if subject and details and name:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                is_valid, error_msg = validate_complaint_data(subject, details, name)
                
                if is_valid:
                    try:
                        complaint_id = save_complaint(subject, details, name)
                        st.success(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ID: {complaint_id}")
                        st.balloons()
                        
                        # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
                        st.session_state.complaint_history = []
                    except Exception as e:
                        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {e}")
                else:
                    st.error(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {error_msg}")
            else:
                st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà")
        
        st.rerun()
    
    # Display chat history
    if st.session_state.complaint_history:
        st.markdown("---")
        for msg in st.session_state.complaint_history[-10:]:
            if msg['role'] == 'user':
                st.markdown(f"""
                <div class="chat-message user-message">
                    <strong>üë§ ‡∏Ñ‡∏∏‡∏ì:</strong> {msg['content']}
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="chat-message ai-message">
                    <strong>ü§ñ AI:</strong> {msg['content']}
                </div>
                """, unsafe_allow_html=True)

# ==================== Data Analysis Handler ====================
def handle_data_analysis(api_key: str, model: str, multiple: bool):
    """Handle data analysis interface"""
    
    mode_name = "‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå" if multiple else "‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß"
    st.subheader(f"üìä ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ({mode_name})")
    
    # File upload
    uploaded_files = st.file_uploader(
        f"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON" + (" (‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ)" if multiple else ""),
        type=['json'],
        accept_multiple_files=multiple,
        help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"
    )
    
    if uploaded_files:
        if not multiple:
            uploaded_files = [uploaded_files]
        
        if st.button("üöÄ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", type="primary"):
            st.session_state.dataframes = {}
            
            with st.spinner("üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå..."):
                for file in uploaded_files:
                    file_content = file.read()
                    df, error = load_json_file(file_content)
                    
                    if error:
                        st.error(f"‚ùå {file.name}: {error}")
                    else:
                        df_clean = clean_dataframe(df)
                        if not df_clean.empty:
                            key = file.name.replace('.json', '')
                            st.session_state.dataframes[key] = df_clean
                            st.success(f"‚úÖ {file.name}: {len(df_clean):,} ‡πÅ‡∏ñ‡∏ß, {len(df_clean.columns)} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå")
            
            # Setup LLM
            if st.session_state.dataframes:
                try:
                    st.session_state.llm = create_llm(api_key, model)
                    st.success("‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° AI ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß")
                except Exception as e:
                    st.error(f"‚ùå ‡∏™‡∏£‡πâ‡∏≤‡∏á LLM ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")
    
    # Show data if loaded
    if st.session_state.dataframes:
        st.markdown("---")
        st.subheader(f"üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î ({len(st.session_state.dataframes)} ‡πÑ‡∏ü‡∏•‡πå)")
        
        # Summary metrics
        total_rows = sum(len(df) for df in st.session_state.dataframes.values())
        total_cols = sum(len(df.columns) for df in st.session_state.dataframes.values())
        
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("üìÅ ‡πÑ‡∏ü‡∏•‡πå", len(st.session_state.dataframes))
        col2.metric("üìä ‡πÅ‡∏ñ‡∏ß‡∏£‡∏ß‡∏°", f"{total_rows:,}")
        col3.metric("üìã ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏ß‡∏°", total_cols)
        col4.metric("ü§ñ AI", "‡∏û‡∏£‡πâ‡∏≠‡∏°" if st.session_state.llm else "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°")
        
        # Show dataframes
        for name, df in st.session_state.dataframes.items():
            with st.expander(f"üìÑ {name} ({len(df):,} ‡πÅ‡∏ñ‡∏ß √ó {len(df.columns)} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)", expanded=False):
                
                # Show data info
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå:**", ", ".join(df.columns.tolist()))
                with col2:
                    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
                    if numeric_cols:
                        st.write("**‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç:**", ", ".join(numeric_cols))
                
                # Show data preview
                st.dataframe(df.head(20), use_container_width=True)
                
                # Basic stats for numeric columns
                if numeric_cols:
                    st.write("**‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:**")
                    st.dataframe(df[numeric_cols].describe(), use_container_width=True)
        
        # Chat interface for asking questions
        if st.session_state.llm:
            st.markdown("---")
            st.subheader("üí¨ ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            
            # Example questions
            with st.expander("üí° ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°", expanded=False):
                st.markdown("""
                - ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 10 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å
                - ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡∏µ‡πà‡πÅ‡∏ñ‡∏ß?
                - ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå [‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå]
                - ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ó‡πà‡∏á‡∏Ç‡∏≠‡∏á [‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå]
                - ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î
                - ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÉ‡∏ô [‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå]
                """)
            
            # Question form
            with st.form("question_form", clear_on_submit=True):
                col1, col2 = st.columns([5, 1])
                
                with col1:
                    question = st.text_input(
                        "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°",
                        placeholder="‡πÄ‡∏ä‡πà‡∏ô: ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏µ‡πà‡πÅ‡∏ñ‡∏ß? ‡πÅ‡∏™‡∏î‡∏á 5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å",
                        label_visibility="collapsed"
                    )
                
                with col2:
                    ask_btn = st.form_submit_button("üöÄ ‡∏ñ‡∏≤‡∏°", type="primary", use_container_width=True)
            
            # Process question
            if ask_btn and question:
                with st.spinner("ü§î AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå..."):
                    start = time.time()
                    answer = ask_question_about_data(
                        question,
                        st.session_state.dataframes,
                        st.session_state.llm
                    )
                    elapsed = time.time() - start
                
                st.session_state.chat_history.append({
                    'time': datetime.now().strftime("%H:%M:%S"),
                    'question': question,
                    'answer': answer,
                    'elapsed': f"{elapsed:.2f}s"
                })
                
                st.rerun()
            
            # Show chat history
            if st.session_state.chat_history:
                st.markdown("---")
                st.subheader("üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
                
                for chat in reversed(st.session_state.chat_history[-5:]):
                    st.markdown(f"""
                    <div class="chat-message user-message">
                        <strong>üë§ [{chat['time']}]:</strong> {chat['question']}
                    </div>
                    <div class="chat-message ai-message">
                        <strong>ü§ñ ({chat['elapsed']}):</strong><br/>{chat['answer']}
                    </div>
                    """, unsafe_allow_html=True)
                
                # Clear chat button
                if st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", use_container_width=True):
                    st.session_state.chat_history = []
                    st.session_state.question_cache = {}
                    st.success("‚úÖ ‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß")

# ==================== Main Application ====================
def main():
    """Main application"""
    
    init_session_state()
    init_db()
    
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>üéØ Unified Business Platform</h1>
        <p>‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô + ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
        
        # API Key
        api_key = st.text_input(
            "üîë OpenRouter API Key",
            type="password",
            help="‡∏£‡∏±‡∏ö‡∏ü‡∏£‡∏µ‡∏ó‡∏µ‡πà https://openrouter.ai/keys"
        )
        
        # Model selection
        model = st.selectbox(
            "ü§ñ AI Model",
            [
                "anthropic/claude-3-haiku",
                "anthropic/claude-3-5-sonnet",
                "openai/gpt-4-turbo",
                "openai/gpt-3.5-turbo",
                "google/gemini-pro"
            ],
            help="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ"
        )
        
        # Mode selection
        st.markdown("---")
        st.subheader("üì± ‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        
        mode_options = {
            'home': 'üè† ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å',
            'complaint': 'üí¨ ‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô',
            'single_file': 'üìä ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß',
            'multi_file': 'üìÅ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå',
            'new_mode': 'üìà ‡πÇ‡∏´‡∏°‡∏î‡πÅ‡∏ä‡∏ó'
        }
        
        for mode_key, mode_name in mode_options.items():
            if st.button(
                mode_name, 
                use_container_width=True, 
                type="primary" if st.session_state.mode == mode_key else "secondary"
            ):
                st.session_state.mode = mode_key
                st.rerun()
        
        # Stats
        st.markdown("---")
        st.subheader("üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥")
        stats = st.session_state.api_stats
        col1, col2 = st.columns(2)
        col1.metric("üì° API Calls", stats['requests'])
        col2.metric("‚ùå Errors", stats['errors'])
        col1.metric("üíæ Cache Hits", stats['cache_hits'])
        
        # System status
        st.markdown("---")
        st.subheader("üîß ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡∏∞‡∏ö‡∏ö")
        st.text(f"{'‚úÖ' if api_key else '‚ö†Ô∏è'} API Key")
        st.text(f"{'‚úÖ' if PANDASAI_AVAILABLE else '‚ö†Ô∏è'} PandasAI")
        st.text(f"{'‚úÖ' if st.session_state.llm else '‚ö†Ô∏è'} AI Model")
    
    # Main content based on mode
    if st.session_state.mode == 'home':
        # Home page
        st.subheader("üè† ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà Business Platform")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="mode-card">
                <h3>üí¨ ‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô</h3>
                <p>‚Ä¢ ‡πÅ‡∏ä‡∏ó‡∏Å‡∏±‡∏ö AI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô</p>
                <p>‚Ä¢ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏•‡∏á Database</p>
                <p>‚Ä¢ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢ (RAG)</p>
                <p>‚Ä¢ ‡∏î‡∏π‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="mode-card">
                <h3>üìä ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß</h3>
                <p>‚Ä¢ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î JSON ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß</p>
                <p>‚Ä¢ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ AI</p>
                <p>‚Ä¢ ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥</p>
                <p>‚Ä¢ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥</p>
            </div>
            """, unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="mode-card">
                <h3>üìÅ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå</h3>
                <p>‚Ä¢ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏•‡∏≤‡∏¢ JSON ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô</p>
                <p>‚Ä¢ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≤‡∏°‡∏ï‡∏≤‡∏£‡∏≤‡∏á</p>
                <p>‚Ä¢ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥</p>
                <p>‚Ä¢ ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="mode-card">
                <h3>üìà ‡πÇ‡∏´‡∏°‡∏î‡πÅ‡∏ä‡∏ó</h3>
                <p>‚Ä¢ ‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö AI ‡πÅ‡∏ö‡∏ö‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ</p>
                <p>‚Ä¢ ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢</p>
                <p>‚Ä¢ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤</p>
                <p>‚Ä¢ ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Features
        st.markdown("---")
        st.subheader("‚ú® ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏î‡πà‡∏ô")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            ### üöÄ ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
            - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î
            - ‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ü‡∏ã‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
            - ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
            """)
        
        with col2:
            st.markdown("""
            ### üß† AI ‡∏â‡∏•‡∏≤‡∏î
            - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
            - ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
            - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•
            """)
        
        with col3:
            st.markdown("""
            ### ‚ö° ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î
            - ‡πÅ‡∏Ñ‡∏ä‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ã‡πâ‡∏≥
            - ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï API
            - ‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏±‡∏ô‡πÉ‡∏à
            """)
        
        # Getting started
        st.markdown("---")
        st.info("üëà **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:** ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡πÅ‡∏ñ‡∏ö‡∏ã‡πâ‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà API Key")
        
        with st.expander("‚ùì ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ö API Key ‡∏ü‡∏£‡∏µ"):
            st.markdown("""
            1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà https://openrouter.ai/keys
            2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏±‡∏ç‡∏ä‡∏µ (‡∏ü‡∏£‡∏µ)
            3. ‡∏Ñ‡∏•‡∏¥‡∏Å "Create Key"
            4. Copy API Key ‡∏°‡∏≤‡πÉ‡∏™‡πà‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ö‡∏ã‡πâ‡∏≤‡∏¢
            5. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            """)
    
    elif st.session_state.mode == 'complaint':
        if not api_key:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà API Key ‡∏ó‡∏µ‡πà‡πÅ‡∏ñ‡∏ö‡∏ã‡πâ‡∏≤‡∏¢")
        else:
            handle_complaint_chat(api_key, model)
    
    elif st.session_state.mode == 'single_file':
        if not PANDASAI_AVAILABLE:
            st.error("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á: `pip install pandasai requests`")
            return
        
        if not api_key:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà API Key ‡∏ó‡∏µ‡πà‡πÅ‡∏ñ‡∏ö‡∏ã‡πâ‡∏≤‡∏¢")
            return
        
        handle_data_analysis(api_key, model, multiple=False)
    
    elif st.session_state.mode == 'multi_file':
        if not PANDASAI_AVAILABLE:
            st.error("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á: `pip install pandasai requests`")
            return
        
        if not api_key:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà API Key ‡∏ó‡∏µ‡πà‡πÅ‡∏ñ‡∏ö‡∏ã‡πâ‡∏≤‡∏¢")
            return
        
        handle_data_analysis(api_key, model, multiple=True)
    
    elif st.session_state.mode == 'new_mode':
        if not api_key:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà API Key ‡∏ó‡∏µ‡πà‡πÅ‡∏ñ‡∏ö‡∏ã‡πâ‡∏≤‡∏¢")
        else:
            handle_new_mode_chat(api_key, model)
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666; padding: 1rem;'>
        <p><strong>üéØ Unified Business Platform</strong></p>
        <p style='font-size: 0.9em;'>
            ‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‚Ä¢ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Ä¢ ‡πÅ‡∏ä‡∏ó‡∏Å‡∏±‡∏ö AI ‚Ä¢ ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
        </p>
        <p style='font-size: 0.8em; color: #999;'>
            Powered by PandasAI & OpenRouter | Version 2.0 | Made with ‚ù§Ô∏è in Thailand
        </p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"""
        ### ‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
        
        **‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:** {str(e)}
        
        **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**
        
        1. **‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies:**
        ```bash
        pip install streamlit pandas plotly pandasai requests
        ```
        
        2. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API Key:**
        - ‡πÑ‡∏õ‡∏ó‡∏µ‡πà https://openrouter.ai/keys
        - ‡∏™‡∏£‡πâ‡∏≤‡∏á API Key ‡πÉ‡∏´‡∏°‡πà
        - Copy ‡∏°‡∏≤‡πÉ‡∏™‡πà‡πÉ‡∏ô‡πÅ‡∏≠‡∏õ
        
        3. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå JSON:**
        - ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô valid JSON format
        - ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ JSONLint.com ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
        
        4. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Python Version:**
        - ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô Python 3.8 ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ
        """)
        
        if st.button("üîÑ ‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡πÅ‡∏≠‡∏õ", type="primary"):
            st.rerun()